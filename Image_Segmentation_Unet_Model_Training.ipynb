{
  "cells": [
    {
      "metadata": {
        "id": "d610e41ff6143034"
      },
      "cell_type": "markdown",
      "source": [
        "## EMATM0047: Data Science Project\n",
        "---\n",
        "### Code Section S2.1: Image segmentation - Unet model training section\n",
        "#### Author: Alan Liu\n",
        "#### Faculty of Engineering\n",
        "#### University of Bristol\n",
        "\n",
        "Input:\n",
        "1. the cryo-EM picture, 4 stages with 100 .mrc each, 400 files in total.\n",
        "2. the corresponding V4 mask, 4 stages with 100 .npy each, 400 files in total.\n",
        "\n",
        "Operation:\n",
        "1. Construct the DataLoader\n",
        "2. Use the Unet model for 7 classes\n",
        "3. Genertate the segmentation results based on the optimal weights"
      ],
      "id": "d610e41ff6143034"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Connect to Google drive"
      ],
      "metadata": {
        "id": "5x6X29npfOhz"
      },
      "id": "5x6X29npfOhz"
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "IA1kP0YGfIR0"
      },
      "id": "IA1kP0YGfIR0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check if mrcfile is installed\n",
        "try:\n",
        "  import mrcfile\n",
        "  print(\"Yes\")\n",
        "except:\n",
        "  print(\"No\")\n",
        "  !pip install mrcfile\n",
        "  print()\n",
        "  print(\"mrcfile package installed, continue.\")"
      ],
      "metadata": {
        "id": "JHNcQu8EgymV"
      },
      "id": "JHNcQu8EgymV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "id": "initial_id",
      "metadata": {
        "collapsed": true,
        "id": "initial_id"
      },
      "source": [
        "# step 1: construct the dataloader\n",
        "# the original mrc file won't be fitted into the model\n",
        "# but be segmented into patches\n",
        "# This operation can increase the percentage of cell pixel\n",
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import mrcfile\n",
        "from pathlib import Path\n",
        "import random\n",
        "from typing import Dict, List, Tuple, Optional\n",
        "from collections import defaultdict\n",
        "\n",
        "# set the random seed to make sure the result can be reproduced\n",
        "seed = 426 # according to my ID\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "\n",
        "class PatchBasedData(Dataset):\n",
        "    \"\"\"\n",
        "    process the original dataset with the patch_based approach\n",
        "\n",
        "    the process steps are:\n",
        "    1. Find all MRC and mask files\n",
        "    1. For file with cells: generate patches around the cells\n",
        "    2. For file without cells: generate patches randomly\n",
        "    3. all patches are restricted with the same size of 256 * 256\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, base_dir: str = \"/content/drive/MyDrive/Final Project\",\n",
        "                 stages: Optional[List[int]] = None, # which stage to process\n",
        "                 patch_size: int = 256, # size of patch, Note; this number must be lower than h, w of mask\n",
        "                 patches_per_image: int = 24, # how many patches are needed for one mrc file\n",
        "                 bg_patches_per_image: int = 12): # how many are needed, for no-cell mrc file\n",
        "\n",
        "\n",
        "        self.base_dir = Path(base_dir)\n",
        "        self.patch_size = patch_size\n",
        "        self.patches_per_image = patches_per_image\n",
        "        self.bg_patches_per_image = bg_patches_per_image\n",
        "\n",
        "        # stage mapping\n",
        "        # because the name of stage folder of mrc and npy are different\n",
        "        self.stage_mapping = {1: {'mrc': 'stageI', 'mask': 'stage1'},\n",
        "                    2: {'mrc': 'stageII', 'mask': 'stage2'},\n",
        "                    3: {'mrc': 'stageIII', 'mask': 'stage3'},\n",
        "                    4: {'mrc': 'stageIV', 'mask': 'stage4'}}\n",
        "\n",
        "        # all 4 stages will be processed as default\n",
        "        if stages is None:\n",
        "            stages = [1, 2, 3, 4]\n",
        "        self.stages = stages\n",
        "\n",
        "        # load all files\n",
        "        self.data_pairs = []\n",
        "        self.load_file_paths()\n",
        "\n",
        "        # pre_load data\n",
        "        self.cache_mrc = {}\n",
        "        self.cache_mask = {}\n",
        "        self.preload_data()\n",
        "\n",
        "        # generate all patches\n",
        "        self.patches = []\n",
        "        self.generate_all_patches()\n",
        "\n",
        "    def load_file_paths(self):\n",
        "        \"\"\"\n",
        "        load the mrc and mask file\n",
        "        save them as pairs\n",
        "        \"\"\"\n",
        "        # note: this path is exclusive to my computer\n",
        "        # it may be changed in different devices\n",
        "        mrc_base = self.base_dir / \"Dataset-processed\"\n",
        "        mask_base = self.base_dir / \"Image-segmentation-Level-4\"\n",
        "\n",
        "        # get the stage folder\n",
        "        for stage in self.stages:\n",
        "            mrc_dir = mrc_base / self.stage_mapping[stage]['mrc']\n",
        "            mask_dir = mask_base / self.stage_mapping[stage]['mask']\n",
        "\n",
        "            # get all mrc files\n",
        "            mrc_files = sorted([f for f in os.listdir(mrc_dir) if f.endswith('.mrc')]) # we also have svg in that folder\n",
        "\n",
        "            # get the npy on the basis of each mrc\n",
        "            for mrc_file in mrc_files:\n",
        "                # the path of one mrc\n",
        "                mrc_path = mrc_dir / mrc_file\n",
        "                # construct the name of mask with mrc\n",
        "                mask_file = f\"mask_{mrc_file.split('.')[0]}_v4.npy\"\n",
        "                # the path of the mask\n",
        "                mask_path = mask_dir / mask_file\n",
        "\n",
        "                # if pair is found, save them with the stage label\n",
        "                if mrc_path.exists() and mask_path.exists():\n",
        "                    self.data_pairs.append({'mrc_path': mrc_path,\n",
        "                                'mask_path': mask_path,\n",
        "                                'stage': stage})\n",
        "                else:\n",
        "                    print(f\"Missing file: {mrc_path} or {mask_path}\")\n",
        "                    continue\n",
        "\n",
        "        # the correct/ideal number: len(self.stages) * 100\n",
        "        print(f\"{len(self.data_pairs)} pairs in total\")\n",
        "\n",
        "    def preload_data(self):\n",
        "        \"\"\"\n",
        "        pre-load the data into memory\n",
        "        \"\"\"\n",
        "        self.cache_mrc = {}\n",
        "        self.cache_mask = {}\n",
        "        # load and cache the mrc and mask\n",
        "        for idx, pair in enumerate(tqdm(self.data_pairs, desc = 'Loading data')):\n",
        "            # load mrc\n",
        "            mrc_data = self.load_mrc(pair['mrc_path'])\n",
        "            # normalize mrc\n",
        "            mrc_data = self.normalize_mrc(mrc_data)\n",
        "            # load mask\n",
        "            mask_data = np.load(pair['mask_path'])\n",
        "\n",
        "            # cache them\n",
        "            self.cache_mrc[idx] = mrc_data\n",
        "            self.cache_mask[idx] = mask_data\n",
        "\n",
        "\n",
        "    def generate_all_patches(self):\n",
        "        \"\"\"\n",
        "        generate the patches for all files\n",
        "        \"\"\"\n",
        "        print(\"Generating patches, please wait\")\n",
        "\n",
        "        # number of no cell mask\n",
        "        no_cell_images = 0\n",
        "\n",
        "        for idx, pair in enumerate(tqdm(self.data_pairs, desc = 'generating patches')):\n",
        "            # load the npy\n",
        "            mask = np.load(pair['mask_path'])\n",
        "            # the corresponding stage label\n",
        "            stage = pair['stage']\n",
        "\n",
        "            # find all positions of the cell and return (rows, columns)\n",
        "            cell_positions = np.where(mask == stage)\n",
        "\n",
        "            if len(cell_positions[0]) > 0:\n",
        "                # cell patch\n",
        "                self.generate_cell_patches(idx, mask, stage)\n",
        "            else:\n",
        "                # no cell patch\n",
        "                no_cell_images += 1\n",
        "                self.generate_background_patches(idx, mask, stage)\n",
        "\n",
        "        print(f\"Found {no_cell_images} images without cells\")\n",
        "        print(f\"Generated {len(self.patches)} total patches\")\n",
        "\n",
        "\n",
        "    def generate_cell_patches(self, pair_idx, mask, stage):\n",
        "        \"\"\"\n",
        "        generate the patches for mrc that have cells\n",
        "\n",
        "        argument:\n",
        "        pair_idx: the index of the pair\n",
        "        mask: the Numpy array mask\n",
        "        stage: the stage label\n",
        "        \"\"\"\n",
        "        # get the mask shape\n",
        "        h, w = mask.shape\n",
        "\n",
        "        # define the stride, half of patch size\n",
        "        stride = self.patch_size // 2\n",
        "\n",
        "        # the list storing the x,y and ratio\n",
        "        patch_in_single = []\n",
        "\n",
        "        # get all patch\n",
        "        for y in range(0, h - self.patch_size + 1, stride):\n",
        "            for x in range(0, w - self.patch_size + 1, stride):\n",
        "\n",
        "              patch = mask[y:y + self.patch_size, x:x + self.patch_size]\n",
        "\n",
        "              # valid pixel only\n",
        "              all_valid = (patch != -1)\n",
        "\n",
        "              # there could have all -1 patch, in actual running\n",
        "              valid_sum = int(np.count_nonzero(all_valid))\n",
        "              if valid_sum == 0:\n",
        "                continue\n",
        "\n",
        "              # get the foregraound ratio: (patch == stage) / all_valid\n",
        "              foreground_pixel = int(((patch == stage) & all_valid).sum())\n",
        "              ratio = float(foreground_pixel) / float(all_valid.sum())\n",
        "\n",
        "              # store the info\n",
        "              patch_in_single.append((x, y, ratio))\n",
        "\n",
        "        # here we use top-K to select patch\n",
        "        # 24 from top\n",
        "        k_need = self.patches_per_image\n",
        "\n",
        "        # sorting based on ratio\n",
        "        patch_in_single.sort(key = lambda t: t[2], reverse = True)\n",
        "        # top-k selection\n",
        "        top_K = patch_in_single[:k_need]\n",
        "\n",
        "        # record the info\n",
        "        for (x, y, ratio) in top_K:\n",
        "          self.patches.append({'image_idx': pair_idx,\n",
        "                    'y': y,\n",
        "                    'x': x,\n",
        "                    'stage': stage,\n",
        "                    'has_cells': True})\n",
        "\n",
        "\n",
        "    def generate_background_patches(self, pair_idx, mask, stage):\n",
        "        \"\"\"\n",
        "        generate patches for mrc that have no cells\n",
        "\n",
        "        argument:\n",
        "        pair_idx: the index of the pair\n",
        "        mask: the Numpy array mask\n",
        "        stage: the stage label\n",
        "        \"\"\"\n",
        "        # get the mask size\n",
        "        h, w = mask.shape\n",
        "\n",
        "        bg_patches = 0\n",
        "        # get 10 patches randomly\n",
        "        while bg_patches < self.bg_patches_per_image:\n",
        "            # get a random coordinate\n",
        "            # make sure inside the mask\n",
        "            y = random.randint(0, h - self.patch_size)\n",
        "            x = random.randint(0, w - self.patch_size)\n",
        "\n",
        "            # save the patch\n",
        "            self.patches.append({'image_idx': pair_idx,\n",
        "                      'y': y,\n",
        "                      'x': x,\n",
        "                      'stage': stage,\n",
        "                      'has_cells': False})\n",
        "            bg_patches += 1\n",
        "\n",
        "\n",
        "    def load_mrc(self, path: Path) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        load the mrc file\n",
        "\n",
        "        argument:\n",
        "        path: the path of the mrc file\n",
        "        \"\"\"\n",
        "        with mrcfile.open(path, mode = 'r') as mrc:\n",
        "            data = mrc.data.copy()\n",
        "        return data\n",
        "\n",
        "    def normalize_mrc(self, data: np.ndarray) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        normalize the mrc data following the '_load_mrc()'\n",
        "\n",
        "        argument:\n",
        "        data: the mrc data to be normalized\n",
        "        \"\"\"\n",
        "        # use the quantile normalization\n",
        "        # get the 1st percentile and 99th percentile\n",
        "        p1, p99 = np.percentile(data, [1, 99])\n",
        "        # clip the data\n",
        "        data = np.clip(data, p1, p99)\n",
        "        # then map the data to [0, 1]\n",
        "        data = (data - p1) / (p99 - p1 + 1e-8)\n",
        "        return data\n",
        "\n",
        "    def __len__(self):\n",
        "        # how many patches in total\n",
        "        return len(self.patches)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        \"\"\"\n",
        "        the actual program to get the patch\n",
        "\n",
        "        argument:\n",
        "        idx: the index of the patch\n",
        "        \"\"\"\n",
        "        # get the tuple contains ('image_idx','y','x','stage','has_cell')\n",
        "        patch_info = self.patches[idx]\n",
        "        # get the index of the pair\n",
        "        image_idx = patch_info['image_idx']\n",
        "\n",
        "        # get data from cache\n",
        "        mrc_data = self.cache_mrc[image_idx]\n",
        "        mask_data = self.cache_mask[image_idx]\n",
        "\n",
        "        # get the coordinates\n",
        "        y = patch_info['y']\n",
        "        x = patch_info['x']\n",
        "        # clip the mrc\n",
        "        patch_mrc = mrc_data[y:y + self.patch_size, x:x + self.patch_size]\n",
        "        # clip the mask\n",
        "        patch_mask = mask_data[y:y + self.patch_size, x:x + self.patch_size]\n",
        "\n",
        "        # the size of original mrc is (H, W)\n",
        "        if patch_mrc.ndim == 2:\n",
        "            # add it to [1, H, W], suitable for PyTorch\n",
        "            patch_mrc = patch_mrc[None,:,:]\n",
        "\n",
        "        # rewrite the mask\n",
        "        # the background of stage 4 is different from others\n",
        "        # thus, we allocate a new label to it\n",
        "        if patch_info['stage'] == 4:\n",
        "          patch_mask[patch_mask == 0] = 5\n",
        "\n",
        "        # for \"-1\" label, map it to 255\n",
        "        patch_mask[patch_mask == -1] = 255\n",
        "\n",
        "        # shift to tensor\n",
        "        # float for mrc\n",
        "        patch_mrc = torch.from_numpy(patch_mrc).float()\n",
        "        # long for mask, calculate loss\n",
        "        patch_mask = torch.from_numpy(patch_mask).long()\n",
        "\n",
        "        return {'image': patch_mrc,\n",
        "            'mask': patch_mask,\n",
        "            'stage': patch_info['stage'],\n",
        "            'has_cells': patch_info['has_cells']}\n",
        "\n",
        "\n",
        "def calculate_batch_statistics(batch):\n",
        "    \"\"\"\n",
        "    calculate the statistics of a batch\n",
        "\n",
        "    argument: batch: the batch created by dataloader\n",
        "    \"\"\"\n",
        "    # get all mask patches in a batch\n",
        "    masks = batch['mask']\n",
        "    # dict to store\n",
        "    stats = defaultdict(int)\n",
        "\n",
        "    for mask in masks:\n",
        "        # get each label and their counts\n",
        "        label, counts = torch.unique(mask, return_counts = True)\n",
        "        for label, counts in zip(label.tolist(), counts.tolist()):\n",
        "            # record them\n",
        "            stats[label] += counts\n",
        "    # the total pixels\n",
        "    total = sum(stats.values())\n",
        "    # the valid pixels, by excluding the 255\n",
        "    valid = total - stats.get(255, 0)\n",
        "    # the cell pixels\n",
        "    # [1,2,3,4] are cells\n",
        "    cell_pixels = sum(v for k, v in stats.items() if k in [1, 2, 3, 4])\n",
        "    # summary and return\n",
        "    return {'total_pixels': total,\n",
        "        'valid_pixels': valid,\n",
        "        'cell_ratio': cell_pixels / valid,\n",
        "        'patches_with_cells': sum(batch['has_cells'])}\n",
        "\n",
        "\n",
        "def create_dataloaders(base_dir: str = \"/content/drive/MyDrive/Final Project\",\n",
        "            stages: Optional[List[int]] = None,\n",
        "            batch_size: int = 32,\n",
        "            patch_size: int = 256,\n",
        "            num_workers: int = 2,\n",
        "            val_split: float = 0.2):\n",
        "    \"\"\"\n",
        "    create dataloaders for training and validation\n",
        "\n",
        "    argument:\n",
        "    base_dir: the root directory of the dataset\n",
        "    stages: which stages to process\n",
        "    batch_size: hwo many patches in each batch\n",
        "    patch_size: the size of each patch\n",
        "    num_workers: Number of subprocesses, 0 in windows and changeable in Colab\n",
        "    val_split: the percentage of the validation set\n",
        "    \"\"\"\n",
        "    # get the patch_based dataset\n",
        "    dataset = PatchBasedData(base_dir = base_dir, stages = stages, patch_size = patch_size)\n",
        "\n",
        "    # get the size of training and validation dataset\n",
        "    total_size = len(dataset)\n",
        "    val_size = int(total_size * val_split)\n",
        "    train_size = total_size - val_size\n",
        "\n",
        "    # split the dataset\n",
        "    train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
        "\n",
        "    # construct the training dataloader\n",
        "    train_loader = DataLoader(train_dataset, batch_size = batch_size, shuffle = True, num_workers = num_workers,\n",
        "                  pin_memory = True)\n",
        "    # construct the validation dataloader\n",
        "    val_loader = DataLoader(val_dataset, batch_size = batch_size, shuffle = False, num_workers = num_workers,\n",
        "                 pin_memory = True)\n",
        "\n",
        "    return train_loader, val_loader"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# construct a typical Unet model\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch import optim\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "# we first construct this \"double convolution\" block\n",
        "# inherit from nn.Module\n",
        "class DoubleConv(nn.Module):\n",
        "    \"\"\"\n",
        "    the standard convolution block of Unet\n",
        "\n",
        "    the structure of it: (conv -> BatchNorm -> ReLU) * 2\n",
        "\n",
        "    argument:\n",
        "    in_channels: the number of input channels\n",
        "    out_channels: the number of output channels\n",
        "    \"\"\"\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        # inherit from nn.Module\n",
        "        super().__init__()\n",
        "        # sequential container\n",
        "        self.double_conv = nn.Sequential(\n",
        "            # 3 x 3 convoluation, with padding to keep shape\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size = 3, padding = 1),\n",
        "            # Batchnorm, drop covariate shift\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            # introduce non-linearly\n",
        "            nn.ReLU(inplace = True),\n",
        "            # second convolution\n",
        "            nn.Conv2d(out_channels, out_channels, kernel_size = 3, padding = 1),\n",
        "            # second Batch Normalization\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            # ReLU again\n",
        "            nn.ReLU(inplace = True))\n",
        "    # forward propagation\n",
        "    def forward(self, x):\n",
        "        return self.double_conv(x)\n",
        "\n",
        "# the Unet\n",
        "# Encoder(contracting path): downsampling\n",
        "# Decoder(expansive path): upsampling\n",
        "class UNet(nn.Module):\n",
        "    \"\"\"\n",
        "    the typical Unet model\n",
        "\n",
        "    also inherit from nn.Module\n",
        "    \"\"\"\n",
        "    def __init__(self, n_channels = 1, n_classes = 7):\n",
        "        \"\"\"\n",
        "        initialize the Unet model\n",
        "\n",
        "        argument:\n",
        "        n_channels: the number of input channels\n",
        "        how to set this? 1 for grayscale image, 3 for RGB image, 4 for RGBA image\n",
        "        n_classes: how many classes for output\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.n_channels = n_channels\n",
        "        self.n_classes = n_classes\n",
        "\n",
        "        # 1st double conv, to 64 channels\n",
        "        self.begin = DoubleConv(n_channels, 64)\n",
        "\n",
        "        # 1st downsampling, then again double conv\n",
        "        self.down1 = nn.Sequential(nn.MaxPool2d(2), DoubleConv(64, 128))\n",
        "        # 2nd downsampling, then again double conv\n",
        "        self.down2 = nn.Sequential(nn.MaxPool2d(2), DoubleConv(128, 256))\n",
        "        # 3rd downsampling, then again double conv\n",
        "        self.down3 = nn.Sequential(nn.MaxPool2d(2), DoubleConv(256, 512))\n",
        "        # 4th downsampling, then again double conv\n",
        "        self.down4 = nn.Sequential(nn.MaxPool2d(2), DoubleConv(512, 1024))\n",
        "\n",
        "        # 1st upsampling, then double conv\n",
        "        # kernel_size + stride to double the size of feature map\n",
        "        self.up1 = nn.ConvTranspose2d(1024, 512, kernel_size = 2, stride = 2)\n",
        "        self.conv1 = DoubleConv(1024, 512)\n",
        "        # 2nd upsampling, then double conv\n",
        "        self.up2 = nn.ConvTranspose2d(512, 256, kernel_size = 2, stride = 2)\n",
        "        self.conv2 = DoubleConv(512, 256)\n",
        "        # 3rd upsampling, then double conv\n",
        "        self.up3 = nn.ConvTranspose2d(256, 128, kernel_size = 2, stride = 2)\n",
        "        self.conv3 = DoubleConv(256, 128)\n",
        "        # 4th upsampling, then double conv\n",
        "        self.up4 = nn.ConvTranspose2d(128, 64, kernel_size = 2, stride = 2)\n",
        "        self.conv4 = DoubleConv(128, 64)\n",
        "\n",
        "        # get the logits with 1 x 1 convoluation\n",
        "        self.outcome = nn.Conv2d(64, n_classes, kernel_size = 1)\n",
        "\n",
        "    # forward propagation\n",
        "    def forward(self, x):\n",
        "        x1 = self.begin(x) # 64\n",
        "        x2 = self.down1(x1) # 128\n",
        "        x3 = self.down2(x2) # 256\n",
        "        x4 = self.down3(x3) # 512\n",
        "        x5 = self.down4(x4) # 1024\n",
        "\n",
        "        x6 = self.up1(x5) # 512\n",
        "        x6 = torch.cat([x6, x4], dim = 1)\n",
        "        x6 = self.conv1(x6)\n",
        "\n",
        "        # second upsampling\n",
        "        x7 = self.up2(x6) # 256\n",
        "        x7 = torch.cat([x7, x3], dim = 1)\n",
        "        x7 = self.conv2(x7)\n",
        "\n",
        "        # third upsampling\n",
        "        x8 = self.up3(x7) # 128\n",
        "        x8 = torch.cat([x8, x2], dim = 1)\n",
        "        x8 = self.conv3(x8)\n",
        "\n",
        "        # final upsampling\n",
        "        x9 = self.up4(x8) # 64\n",
        "        x9 = torch.cat([x9, x1], dim = 1)\n",
        "        x9 = self.conv4(x9) # 64\n",
        "\n",
        "        # 64 channels -> 2 classes\n",
        "        logits = self.outcome(x9)\n",
        "        return logits\n",
        "\n",
        "# hybrid loss function is implement: soft dice loss + CrossEntropy\n",
        "# CrossEntropy: used to ignore the 255 label\n",
        "# Dice loss: can tackle the category imbalance problem\n",
        "class DiceLoss(nn.Module):\n",
        "    \"\"\"\n",
        "    calculate the dice loss\n",
        "    \"\"\"\n",
        "    def __init__(self, smooth = 1.0, ignore_index = 255):\n",
        "        super().__init__()\n",
        "        # smoothing factor to prevent zero denominator\n",
        "        self.smooth = smooth\n",
        "        self.ignore_index = ignore_index\n",
        "\n",
        "    def forward(self, input, target):\n",
        "        # get the probability of each label\n",
        "        # logits: [B, C, H, W]\n",
        "        all_probs = F.softmax(input, dim = 1)\n",
        "\n",
        "        # ignore 255\n",
        "        valid_mask = target != self.ignore_index\n",
        "\n",
        "        # sum the loss for each label\n",
        "        total_loss = 0\n",
        "        classes = input.shape[1]\n",
        "\n",
        "        # in each class\n",
        "        for one_class in range(classes):\n",
        "\n",
        "            # get its probability\n",
        "            prob = all_probs[:, one_class]\n",
        "\n",
        "            # shift the ground truth to 1/0\n",
        "            real = (target == one_class).float()\n",
        "\n",
        "            # in valid zone only\n",
        "            prob = prob[valid_mask]\n",
        "            real = real[valid_mask]\n",
        "\n",
        "            # calculate the dice coefficeint\n",
        "            # calculate dice coefficient: (2 * inter * smooth) / (sum(prob) + sum(real) + smooth)\n",
        "            # inter: the probability on right label\n",
        "            intersection = (prob * real).sum()\n",
        "            dice = (2. * intersection + self.smooth) / (prob.sum() + real.sum() + self.smooth)\n",
        "\n",
        "            # sum to total loss\n",
        "            total_loss += (1 - dice)\n",
        "\n",
        "        return total_loss / classes\n",
        "\n",
        "# combine the dice loss to CrossEntropy\n",
        "class DiceCELoss(nn.Module):\n",
        "  \"\"\"\n",
        "  conbine the Dice loss and CrossEntropy loss\n",
        "  \"\"\"\n",
        "  def __init__(self, dice_weight = 0.7, ce_weight = 0.3):\n",
        "    \"\"\"\n",
        "    argument:\n",
        "    dice_weight: the weight of Dice loss\n",
        "    ce_weight: the weight of CrossEntropy loss\n",
        "    \"\"\"\n",
        "    super().__init__()\n",
        "    self.dice_weight = dice_weight\n",
        "    self.ce_weight = ce_weight\n",
        "\n",
        "    # the crossentropy with ignore index\n",
        "    self.ce = nn.CrossEntropyLoss(ignore_index = 255)\n",
        "    # set up the dice loss\n",
        "    self.dice = DiceLoss()\n",
        "\n",
        "  def forward(self, input, target):\n",
        "    # calculate crossentropy Loss\n",
        "    ce_loss = self.ce(input, target)\n",
        "\n",
        "    # calculate dice loss\n",
        "    dice_loss = self.dice(input, target)\n",
        "\n",
        "    # combine them\n",
        "    total_loss = self.ce_weight * ce_loss + self.dice_weight * dice_loss\n",
        "\n",
        "    return total_loss\n",
        "\n",
        "def train_model(model, train_loader, val_loader, epochs = 30, lr = 1e-5, device = 'cuda', save_path = \"Unet_seg_weights.pth\",\n",
        "        dice_weight = 0.5, ce_weight = 0.3):\n",
        "    \"\"\"\n",
        "    model training section\n",
        "\n",
        "    argument:\n",
        "    model: the Unet model\n",
        "    train_loader: the training dataloader\n",
        "    val_loader: the validation dataloader\n",
        "    epochs: how many epochs to train\n",
        "    lr: the learning rate\n",
        "    device: where to train the model, 'cuda' or 'cpu'\n",
        "    \"\"\"\n",
        "\n",
        "    # move the model to cuda\n",
        "    model = model.to(device)\n",
        "    # loss function\n",
        "    criterion = DiceCELoss(dice_weight = dice_weight, ce_weight = ce_weight)\n",
        "    # optimizer: use AdamW\n",
        "    optimizer = optim.AdamW(model.parameters(), lr = lr, weight_decay = 1e-4)\n",
        "    # learning rate scheduler, use cosine annealing\n",
        "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max = epochs, eta_min = 0.0)\n",
        "    # best val loss\n",
        "    best_val_iou = 0\n",
        "\n",
        "    # 1,2,3,4 only\n",
        "    particle_class = [1,2,3,4]\n",
        "\n",
        "    # include 0 as well\n",
        "    all_class = [0,1,2,3,4]\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        # the loss of the training set\n",
        "        train_loss = 0.0\n",
        "        # calculate the IOU\n",
        "        train_iou = {stage: {'inter': 0, 'union': 0} for stage in particle_class}\n",
        "\n",
        "        # use the tqdm to show the progress bar\n",
        "        pbar = tqdm(train_loader, desc = f'Epoch {epoch + 1} / {epochs} [Train]')\n",
        "        for batch in pbar:\n",
        "            # clear the gradient\n",
        "            optimizer.zero_grad()\n",
        "            # input the mrc and mask\n",
        "            images = batch['image'].to(device)\n",
        "            masks = batch['mask'].to(device)\n",
        "            # prediction\n",
        "            outputs = model(images)\n",
        "            # calculate the loss\n",
        "            loss = criterion(outputs, masks)\n",
        "            # back propagation\n",
        "            loss.backward()\n",
        "            # update weights with Adam\n",
        "            optimizer.step()\n",
        "            # add to sum loss\n",
        "            train_loss += loss.item()\n",
        "\n",
        "            # calculate the mIOU_particle, use 1,2,3,4 only\n",
        "            # close gredient for safety\n",
        "            with torch.no_grad():\n",
        "\n",
        "                # get the label prediction\n",
        "                pred = outputs.argmax(dim = 1)\n",
        "                # valid pixels only, exclude black border as well\n",
        "                valid = (masks != 255) & (masks != 6)\n",
        "                for one_class in particle_class:\n",
        "                    # valid prediction for one label\n",
        "                    pred_class = (pred == one_class) & valid\n",
        "                    # valid real mask for one label\n",
        "                    mask_class = (masks == one_class) & valid\n",
        "                    # intersection and union\n",
        "                    inter = (pred_class & mask_class).sum().item()\n",
        "                    union = (pred_class | mask_class).sum().item()\n",
        "                    train_iou[one_class]['inter'] += inter\n",
        "                    train_iou[one_class]['union'] += union\n",
        "\n",
        "            # show the batch loss\n",
        "            pbar.set_postfix({'loss': f'{loss.item():.4f}'})\n",
        "\n",
        "        # get the epoch loss\n",
        "        train_loss /= len(train_loader)\n",
        "        # get the epoch mIOU\n",
        "        mean_iou = []\n",
        "        for one_class in particle_class:\n",
        "            # get union\n",
        "            one_class_union = train_iou[one_class]['union']\n",
        "\n",
        "            # make sure the union above 0\n",
        "            if one_class_union > 0:\n",
        "                iou = train_iou[one_class]['inter'] / train_iou[one_class]['union']\n",
        "                mean_iou.append(iou)\n",
        "        mean_iou = sum(mean_iou) / len(mean_iou)\n",
        "        train_iou = mean_iou if mean_iou > 0 else 0.0\n",
        "\n",
        "        # Validation section\n",
        "        model.eval()\n",
        "        # the loss of the validation set\n",
        "        val_loss = 0.0\n",
        "        # same metrics\n",
        "        val_iou = {stage: {'inter': 0, 'union': 0} for stage in particle_class}\n",
        "\n",
        "        # however, we need more evaluation here, mIOU_all include background\n",
        "        val_iou_all = {stage: {'inter': 0, 'union': 0} for stage in all_class}\n",
        "\n",
        "        # besdies, we want to calculate Dice as well\n",
        "        val_dice = {stage: {'tp': 0, 'fp': 0, 'fn': 0} for stage in all_class}\n",
        "\n",
        "        # the Dice on particle only\n",
        "        val_dice_particle = {stage: {'tp': 0, 'fp': 0, 'fn': 0} for stage in particle_class}\n",
        "\n",
        "        # with no gradient\n",
        "        with torch.inference_mode():\n",
        "            # same bar\n",
        "            for batch in tqdm(val_loader, desc = f'Epoch {epoch + 1} / {epochs} [Val]'):\n",
        "                images = batch['image'].to(device)\n",
        "                masks = batch['mask'].to(device)\n",
        "                outputs = model(images)\n",
        "                # calculate the loss\n",
        "                loss = criterion(outputs, masks)\n",
        "                # add to the validation sum loss\n",
        "                val_loss += loss.item()\n",
        "\n",
        "                # same process to calculate the mIOU_particle\n",
        "                pred = outputs.argmax(dim = 1)\n",
        "                # for valid pixels only, no 255 and no 6\n",
        "                valid = (masks != 255) & (masks != 6)\n",
        "                for one_class in particle_class:\n",
        "                  # get the valid prediction for this class\n",
        "                  pred_class = (pred == one_class) & valid\n",
        "                  # valid ground truth\n",
        "                  mask_class = (masks == one_class) & valid\n",
        "                  # inter and union\n",
        "                  inter = (pred_class & mask_class).sum().item()\n",
        "                  union = (pred_class | mask_class).sum().item()\n",
        "                  val_iou[one_class]['inter'] += inter\n",
        "                  val_iou[one_class]['union'] += union\n",
        "\n",
        "                  # here we also save the Dice values\n",
        "                  tp_particle = inter\n",
        "                  fp_particle = (pred_class & (~mask_class)).sum().item()\n",
        "                  fn_particle = ((~pred_class) & mask_class).sum().item()\n",
        "                  val_dice_particle[one_class]['tp'] += tp_particle\n",
        "                  val_dice_particle[one_class]['fp'] += fp_particle\n",
        "                  val_dice_particle[one_class]['fn'] += fn_particle\n",
        "\n",
        "                # then, we calculate mIOU_all, including background\n",
        "                # copy the mask, habit\n",
        "                mask2 = masks.clone()\n",
        "                # combine the background of all stages\n",
        "                mask2[mask2 == 5] = 0\n",
        "\n",
        "                # copy the output\n",
        "                pred2 = pred.clone()\n",
        "                # combine the background of all stages\n",
        "                pred2[pred2 == 5] = 0\n",
        "\n",
        "                # also set the valid\n",
        "                valid_all = (mask2 != 255) & (mask2 != 6)\n",
        "\n",
        "                # calculate mIOU_all\n",
        "                for one_class in all_class:\n",
        "                  # get the valid prediction for this class\n",
        "                  pred_class_all = (pred2 == one_class) & valid_all\n",
        "                  # valid ground truth\n",
        "                  mask_class_all = (mask2 == one_class) & valid_all\n",
        "                  # inter and union\n",
        "                  inter_all = (pred_class_all & mask_class_all).sum().item()\n",
        "                  union_all = (pred_class_all | mask_class_all).sum().item()\n",
        "                  val_iou_all[one_class]['inter'] += inter_all\n",
        "                  val_iou_all[one_class]['union'] += union_all\n",
        "\n",
        "                  # here we also save the Dice values\n",
        "                  tp = inter_all\n",
        "                  fp = (pred_class_all & (~mask_class_all)).sum().item()\n",
        "                  fn = ((~pred_class_all) & mask_class_all).sum().item()\n",
        "                  val_dice[one_class]['tp'] += tp\n",
        "                  val_dice[one_class]['fp'] += fp\n",
        "                  val_dice[one_class]['fn'] += fn\n",
        "\n",
        "        # get the validation epoch loss\n",
        "        val_loss /= len(val_loader)\n",
        "        # get the vallidation epoch mIOU_particle\n",
        "        mean_val_iou = []\n",
        "        for one_class in particle_class:\n",
        "            # get the union\n",
        "            one_class_union_val = val_iou[one_class]['union']\n",
        "\n",
        "            # make sure the union is above 0\n",
        "            if one_class_union_val > 0:\n",
        "                iou = val_iou[one_class]['inter'] / val_iou[one_class]['union']\n",
        "                mean_val_iou.append(iou)\n",
        "        mean_val_iou = sum(mean_val_iou) / len(mean_val_iou)\n",
        "        val_iou = mean_val_iou if mean_val_iou > 0 else 0.0\n",
        "\n",
        "        # next, calculate the dice\n",
        "        mean_val_dice_particle = []\n",
        "        for one_class in particle_class:\n",
        "            tp_p = val_dice_particle[one_class]['tp']\n",
        "            fp_p = val_dice_particle[one_class]['fp']\n",
        "            fn_p = val_dice_particle[one_class]['fn']\n",
        "\n",
        "            # calculate denominator first\n",
        "            denominator_p = 2 * tp_p + fp_p + fn_p\n",
        "            # make sure the denominator is above 0\n",
        "            if denominator_p > 0:\n",
        "                dice_particle = 2 * tp_p / (2 * tp_p + fp_p + fn_p)\n",
        "                mean_val_dice_particle.append(dice_particle)\n",
        "        mean_val_dice_particle_number = sum(mean_val_dice_particle) / len(mean_val_dice_particle)\n",
        "        val_dice_particle_result = mean_val_dice_particle_number if mean_val_dice_particle_number > 0 else 0.0\n",
        "\n",
        "        # next, calculate the mIOU_all\n",
        "        mean_val_iou_all = []\n",
        "        for one_class in all_class:\n",
        "            # get the union\n",
        "            one_class_union_all = val_iou_all[one_class]['union']\n",
        "\n",
        "            # make sure the union is above 0\n",
        "            if one_class_union_all > 0:\n",
        "                iou = val_iou_all[one_class]['inter'] / val_iou_all[one_class]['union']\n",
        "                mean_val_iou_all.append(iou)\n",
        "        mean_val_iou_all = sum(mean_val_iou_all) / len(mean_val_iou_all)\n",
        "        val_iou_all = mean_val_iou_all if mean_val_iou_all > 0 else 0.0\n",
        "\n",
        "        # next, calculate the dice\n",
        "        mean_val_dice = []\n",
        "        for one_class in all_class:\n",
        "            tp = val_dice[one_class]['tp']\n",
        "            fp = val_dice[one_class]['fp']\n",
        "            fn = val_dice[one_class]['fn']\n",
        "\n",
        "            # calculate denominator first\n",
        "            denominator = 2 * tp + fp + fn\n",
        "            # make sure the denominator is above 0\n",
        "            if denominator > 0:\n",
        "                dice = 2 * tp / (2 * tp + fp + fn)\n",
        "                mean_val_dice.append(dice)\n",
        "        mean_val_dice = sum(mean_val_dice) / len(mean_val_dice)\n",
        "        val_dice = mean_val_dice if mean_val_dice > 0 else 0.0\n",
        "\n",
        "        # scheduler update\n",
        "        scheduler.step()\n",
        "\n",
        "        # print summary\n",
        "        print(f'\\n Epoch {epoch + 1}:')\n",
        "        # training set info\n",
        "        print(f'Train Loss: {train_loss:.4f}, Train mIoU: {train_iou:.4f}')\n",
        "        # validation set info\n",
        "        print(f'Val Loss: {val_loss:.4f}')\n",
        "        print(f'Val mIoU_particle: {val_iou:.4f}, Val Dice_particle: {val_dice_particle_result:.4f}')\n",
        "        print(f'Val mIoU_all: {val_iou_all:.4f}, Val Dice_all: {val_dice:.4f}')\n",
        "        print()\n",
        "\n",
        "        # save the weights of the best model (and keep updating)\n",
        "        if val_iou > best_val_iou:\n",
        "            best_val_iou = val_iou\n",
        "            torch.save(model.state_dict(), save_path)\n",
        "            print('Weights for best model saved')\n",
        "            print()\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "07eFvaiWu-mg"
      },
      "id": "07eFvaiWu-mg",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model training stage\n",
        "\n",
        "During this stage, one model will be created\n",
        "\n",
        "The hyper-parameters will be set as follows:\n",
        "\n",
        "1. patches_per_image, 24\n",
        "2. bg_patches_per_image, 12\n",
        "3. batch_size, 32, 32 patches within a batch\n",
        "4. num_workers: 2\n",
        "5. epochs: 30\n",
        "6. val_split = 0.2, 80% for training and 20% validation\n",
        "\n"
      ],
      "metadata": {
        "id": "YLVICVpv8ZhS"
      },
      "id": "YLVICVpv8ZhS"
    },
    {
      "cell_type": "code",
      "source": [
        "# training\n",
        "def unet_stage():\n",
        "    # construct the dataloader\n",
        "    train_loader, val_loader = create_dataloaders(stages = [1,2,3,4], batch_size = 24, patch_size = 256,\n",
        "                             num_workers = 2, val_split = 0.2)\n",
        "    # get a single batch\n",
        "    for batch in train_loader:\n",
        "        print(f\"Batch shape: {batch['image'].shape}\")\n",
        "        # print the statistic\n",
        "        stats = calculate_batch_statistics(batch)\n",
        "        print(f\"Patches with cells: {stats['patches_with_cells']} / {len(batch['image'])}\")\n",
        "        print(f\"Cell pixel ratio: {stats['cell_ratio'] * 100:.2f}%\")\n",
        "\n",
        "        break\n",
        "    # create the model\n",
        "    model = UNet(n_channels = 1, n_classes = 7)\n",
        "\n",
        "    # device checking\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    print(f\"Using device: {device}\")\n",
        "\n",
        "    # model training\n",
        "    model = train_model(model, train_loader, val_loader, epochs = 30, device = device, lr = 1e-4,\n",
        "               dice_weight = 0.6, ce_weight = 0.4,\n",
        "               save_path = \"/content/drive/MyDrive/Final Project/Image-segmentation-Level-4/Unet_seg_weights.pth\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    unet_stage()\n",
        "    print(\"Model training finished\")"
      ],
      "metadata": {
        "id": "J7D2vgDDp8qB"
      },
      "id": "J7D2vgDDp8qB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# release the RAM\n",
        "import gc\n",
        "gc.collect()"
      ],
      "metadata": {
        "id": "m0PDO7iGrjhj"
      },
      "id": "m0PDO7iGrjhj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Particle picking stage\n",
        "\n",
        "The purpose of this stage is to implement particle picking study based on the above outcome, the saved weights\n",
        "\n",
        "During the validation stage, we have a full-labeled dataset with 4 stages and 17 files\n",
        "\n",
        "However, the original micrographs is stroed in the .tif format, rather than the MRC file\n",
        "\n",
        "Thus, two methods is implemented:\n",
        "\n",
        "1. Pick the right stage particles on the MRC file\n",
        "2. Pick all-stage particles on the TIF file\n",
        "\n",
        "All result will be saved with visual result"
      ],
      "metadata": {
        "id": "85wKB8T0YRKY"
      },
      "id": "85wKB8T0YRKY"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### On the MRC file"
      ],
      "metadata": {
        "id": "1Mi_X96hvy63"
      },
      "id": "1Mi_X96hvy63"
    },
    {
      "cell_type": "code",
      "source": [
        "# import the package\n",
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# normalize first\n",
        "def normalize_data(data):\n",
        "    \"\"\"\n",
        "    mrc normalization\n",
        "\n",
        "    argument:\n",
        "    data: the input data\n",
        "    \"\"\"\n",
        "    # use the quantile normalization\n",
        "    # get the 1st percentile and 99th percentile\n",
        "    p1, p99 = np.percentile(data, [1, 99])\n",
        "    # clip the data\n",
        "    data = np.clip(data, p1, p99)\n",
        "    # then map the data to [0, 1]\n",
        "    data = (data - p1) / (p99 - p1 + 1e-8) # add a 1e-8 to prevent 0\n",
        "    return data\n",
        "\n",
        "def particle_picking(input_file, models, patch_size = 256, stride = 128, device = 'cuda'):\n",
        "  \"\"\"\n",
        "  pick the particle of input files\n",
        "\n",
        "  argument:\n",
        "  file: the input file\n",
        "  models: the used model\n",
        "  patch_size: the size of patch in sliding window sampling\n",
        "  stride: the stride of sliding window sampling\n",
        "  devce: cuda or cpu\n",
        "  \"\"\"\n",
        "\n",
        "  # make sure 2D file\n",
        "  assert input_file.ndim == 2, \"Input file should be 2D\"\n",
        "\n",
        "  # normalize the target file\n",
        "  norm_file = normalize_data(input_file)\n",
        "\n",
        "  # get the file shape\n",
        "  h, w = norm_file.shape\n",
        "\n",
        "  # define the global info\n",
        "  classes = 7\n",
        "  logit_glob = torch.zeros(classes, h, w, device = device, dtype = torch.float32)\n",
        "  count_glob = torch.zeros(h, w, device = device, dtype = torch.float32)\n",
        "\n",
        "  # sliding window sampling\n",
        "  # the range (0, h/w - patch_size + 1)\n",
        "  # this ensures the last one starts from h-patch_size, thus don't cross the line\n",
        "  with torch.no_grad():\n",
        "      for y in range(0, h - patch_size + 1, stride):\n",
        "          for x in range(0, w - patch_size + 1, stride):\n",
        "              # get the patch\n",
        "              patch = norm_file[y:y + patch_size, x:x + patch_size]\n",
        "              # convert to tensor\n",
        "              # now the patch size is (h, w), we want [batch_size, n_channels, h, w]\n",
        "              patch_tensor = torch.from_numpy(patch[None, None]).float().to(device)\n",
        "\n",
        "              # we do mixture of experts, MOE\n",
        "              # fit for logit [C,H,W]\n",
        "              result = models(patch_tensor)[0]\n",
        "              # get probs\n",
        "              probs = F.softmax(result, dim = 0)\n",
        "              # add to the globe\n",
        "              logit_glob[:, y:y + patch_size, x:x + patch_size] += probs\n",
        "              # add to the count\n",
        "              count_glob[y:y + patch_size, x:x + patch_size] += 1.0\n",
        "\n",
        "  # make sure the count is no less than 1\n",
        "  count_glob = torch.clamp(count_glob, min = 1.0)\n",
        "  # get the mean logit, [C,H,W] / [1,H,W]\n",
        "  avg_glob = logit_glob / count_glob.unsqueeze(0)\n",
        "\n",
        "  # get the prediction label\n",
        "  pred_label = torch.argmax(avg_glob, dim = 0)\n",
        "\n",
        "  # get the boolean from foreground mask\n",
        "  pred1 = (pred_label == 1)\n",
        "\n",
        "  pred2 = (pred_label == 2)\n",
        "\n",
        "  pred3 = (pred_label == 3)\n",
        "\n",
        "  pred4 = (pred_label == 4)\n",
        "\n",
        "  return pred1.cpu().numpy(), pred2.cpu().numpy(), pred3.cpu().numpy(), pred4.cpu().numpy(), pred_label.cpu().numpy()"
      ],
      "metadata": {
        "id": "711-RlPkYPvx"
      },
      "id": "711-RlPkYPvx",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# random seed\n",
        "random.seed(2025)\n",
        "\n",
        "# implement the model\n",
        "# specify the device\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "weight_path = '/content/drive/MyDrive/Final Project/Image-segmentation-Level-4/Unet_seg_weights.pth'\n",
        "\n",
        "# create Unet\n",
        "model = UNet(n_channels = 1, n_classes = 7).to(device)\n",
        "# load existed weights\n",
        "model.load_state_dict(torch.load(weight_path, map_location = device))\n",
        "# eval mode\n",
        "model.eval()\n",
        "\n",
        "root_path = Path('/content/drive/MyDrive/Final Project/Dataset-processed')\n",
        "mask_base = Path('/content/drive/MyDrive/Final Project/Image-segmentation-Level-4')\n",
        "\n",
        "# requied mapping\n",
        "stages = {'stageI': 1, 'stageII': 2, 'stageIII': 3, 'stageIV': 4}\n",
        "\n",
        "# define the path to save result\n",
        "out_dir = mask_base / 'Unet_result_on_MRC'\n",
        "os.makedirs(out_dir, exist_ok = True)\n",
        "\n",
        "# extract files\n",
        "for stage in stages.keys():\n",
        "    print(f\"Now extracting from {stage}\")\n",
        "    # connect to get the stage folder path\n",
        "    stage_path = root_path / stage\n",
        "    # find mrc files\n",
        "    all_files = [f for f in os.listdir(stage_path) if f.endswith('.mrc')]\n",
        "    # print choose files\n",
        "    all_files = random.sample(all_files, min(100, len(all_files)))\n",
        "    print(f\"chosen file: {all_files}\")\n",
        "    print()\n",
        "\n",
        "    # make stage folder\n",
        "    stage_dir = out_dir / stage\n",
        "    os.makedirs(stage_dir, exist_ok = True)\n",
        "\n",
        "    # for one file\n",
        "    for one_file in all_files:\n",
        "        percentages = {}\n",
        "        # get the file path\n",
        "        file_path = stage_path / one_file\n",
        "        # read the file\n",
        "        with mrcfile.open(file_path) as mrc:\n",
        "          # convert to float\n",
        "          file_data = mrc.data.astype(np.float32)\n",
        "\n",
        "        # fit the mrc file into model\n",
        "        pred1, pred2, pred3, pred4, pred_mask = particle_picking(file_data, model, patch_size = 256, stride = 128, device = device)\n",
        "\n",
        "        # the percentage of multi-stage mask\n",
        "        for single_stage, corresponding_mask in enumerate([pred1, pred2, pred3, pred4], start = 1):\n",
        "            percentages[single_stage] = float(corresponding_mask.mean() * 100.0)\n",
        "\n",
        "        # draw the plot\n",
        "        norm_origin = normalize_data(file_data.squeeze())\n",
        "        # to [H,W,3]\n",
        "        rgb_origin = np.stack([norm_origin] * 3, axis = -1)\n",
        "        # the mark overlay\n",
        "        overlay = rgb_origin.copy()\n",
        "        # four colors\n",
        "        # stage 1 use blue\n",
        "        overlay[pred1] = [0.0, 0.0, 1.0]\n",
        "        # stage 2 use red\n",
        "        overlay[pred2] = [1.0, 0.0, 0.0]\n",
        "        # stage 3 use yellow\n",
        "        overlay[pred3] = [1.0, 1.0, 0.0]\n",
        "        # stage 4 use pink\n",
        "        overlay[pred4] = [1.0, 0.0, 1.0]\n",
        "        # mix\n",
        "        integrated = 0.6 * rgb_origin + 0.4 * overlay\n",
        "\n",
        "        # file name\n",
        "        name = file_path.stem\n",
        "\n",
        "        # save\n",
        "        stage_dir = out_dir / stage\n",
        "        save_path = stage_dir / f\"{name}_modelpred.png\"\n",
        "        plt.imsave(str(save_path), integrated)\n",
        "\n",
        "        # print statistic\n",
        "        print(f\"File name: {file_path}\")\n",
        "        for the_stage_number, the_percentage in percentages.items():\n",
        "            print(f\"{the_stage_number} percentage: {the_percentage:.2f}%\")\n",
        "        print(f\"Saved to {save_path}\")\n",
        "        print()"
      ],
      "metadata": {
        "id": "smUTZf32fNVU"
      },
      "id": "smUTZf32fNVU",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}